{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f540434-f4d2-419f-95b9-7622f6a21eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.7.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.22.0)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.7.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (75.6.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torchvision) (2.2.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jinja2->torch) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee859ebf-df89-48f1-a3fb-0eb1ef717c7d",
   "metadata": {},
   "source": [
    "# Fake News Detection using BERT\n",
    "\n",
    "This project aims to classify news articles as **real or fake** using a fine-tuned BERT (Bidirectional Encoder Representations from Transformers) model. With the increasing spread of misinformation, automating fake news detection has become crucial. \n",
    "\n",
    "We leverage the power of **transformer-based models** to understand the context and semantics of the news text and make binary predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2b25e3-1057-400b-82e5-bfcaa506645f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b141a9dd-7f30-4e6b-989f-267944dd4820",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fake = pd.read_csv(\"Fake.csv\")\n",
    "df_true = pd.read_csv(\"True.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8634f367-5202-47ef-89f8-aeec7857c240",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fake.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae904d2-77e1-434a-b0e4-4842a6646931",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_true.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c8bd37-aaa9-4677-9c3f-50bc1fdf9f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fake[\"label\"] = 0\n",
    "df_true[\"label\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f6057c-787d-4849-a6cc-b892b2215985",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fake.shape, df_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146f8aa8-5a8c-4ab9-a699-8f053ffaeaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_fake, df_true]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c628cda9-b313-404b-9bbb-e9bf94b3073d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\"title\", \"label\"]].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e38653-fc60-4120-bdf6-45e681d4972e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13fe4a7-68db-4a13-b32e-56e9173283b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97a0b32-d2f9-4e2d-993d-b75a0a16a6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac = 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ca6b10-8422-487e-b6de-6d034a5c05cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordopt(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub(\"\\\\W\",\" \",text) \n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a15d1f-4d13-44a1-9507-b8c94126057e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76afdebf-20e5-45ee-be38-5fbba3def40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"title\"] = df[\"title\"].apply(wordopt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1408f0-df0b-436b-a858-23008c590ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68a5c5e-ccc3-4c53-8347-02906af5a9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot class distribution\n",
    "sns.countplot(data=df, x=\"label\")\n",
    "plt.title(\"Distribution of Fake (0) and Real (1) News\")\n",
    "plt.xlabel(\"Label\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xticks([0, 1], ['Fake', 'Real'])\n",
    "plt.show()\n",
    "\n",
    "# Count values\n",
    "print(df[\"label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecfbfb1-1068-47e1-bc23-a070aa887cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text_length\"] = df[\"title\"].apply(lambda x: len(x.split()))\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(data=df, x=\"text_length\", bins=30, hue=\"label\", kde=True, palette=\"Set2\")\n",
    "plt.title(\"Title Word Count Distribution by Class\")\n",
    "plt.xlabel(\"Number of Words\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.legend(labels=[\"Real\", \"Fake\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2458db5a-1ac1-4072-b41b-5343ea45896d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "fake_titles = df[df['label'] == 0]['title']\n",
    "real_titles = df[df['label'] == 1]['title']\n",
    "\n",
    "# Create wordclouds\n",
    "fake_text = \" \".join(fake_titles)\n",
    "real_text = \" \".join(real_titles)\n",
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "\n",
    "# Fake news word cloud\n",
    "plt.subplot(1, 2, 1)\n",
    "wordcloud_fake = WordCloud(width=800, height=400, background_color='white').generate(fake_text)\n",
    "plt.imshow(wordcloud_fake, interpolation='bilinear')\n",
    "plt.title(\"WordCloud for Fake News\")\n",
    "plt.axis('off')\n",
    "\n",
    "# Real news word cloud\n",
    "plt.subplot(1, 2, 2)\n",
    "wordcloud_real = WordCloud(width=800, height=400, background_color='white').generate(real_text)\n",
    "plt.imshow(wordcloud_real, interpolation='bilinear')\n",
    "plt.title(\"WordCloud for Real News\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7168dc-d490-4597-bd59-2d65df046eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "df['label'].value_counts().plot.pie(autopct='%1.1f%%', labels=['Fake', 'Real'], colors=['red', 'green'])\n",
    "plt.title(\"Fake vs Real News\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49d21d7-bc94-460d-87ba-b3c7cd5303be",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, val_texts, train_labels, val_labels = train_test_split(df[\"title\"], df[\"label\"], test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7699cb23-b7aa-4ef0-8875-d501609afe53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "train_encodings = tokenizer(list(train_texts), truncation=True, padding=True)\n",
    "val_encodings = tokenizer(list(val_texts), truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b483e1-0012-4885-9589-cb6baa1564d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b052debc-140e-4a82-a7ff-11b1867fd72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset conversion\n",
    "class FakeNewsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "    def __getitem__(self, idx):\n",
    "        item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f7a0df-c777-4abf-87da-cca59a1620a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained model\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e93084-6fe6-4932-8379-e638d693e01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define metrics\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"binary\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"f1\": f1, \"precision\": precision, \"recall\": recall}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a5b218-6a6f-46df-8e69-f1df114f2b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "import torch\n",
    "\n",
    "# Combine tokenized inputs and labels\n",
    "train_dataset = Dataset.from_dict({\n",
    "    'input_ids': train_encodings['input_ids'],\n",
    "    'attention_mask': train_encodings['attention_mask'],\n",
    "    'labels': train_labels\n",
    "})\n",
    "\n",
    "val_dataset = Dataset.from_dict({\n",
    "    'input_ids': val_encodings['input_ids'],\n",
    "    'attention_mask': val_encodings['attention_mask'],\n",
    "    'labels': val_labels\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea0f21d-c49a-4f0d-81e8-81e86497b13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=64,\n",
    "    eval_strategy=\"epoch\",  # ← adjusted earlier\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,     \n",
    "    eval_dataset=val_dataset,       \n",
    "    compute_metrics=compute_metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ba6b9c-3935-44ed-a688-cfa9132c2cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07ff602-a1c4-4f29-8f7d-25a422afe2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"saved_model\")\n",
    "tokenizer.save_pretrained(\"saved_model\")\n",
    "print(\"Model and tokenizer saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88163a5e-641f-4b8b-8fea-e3518deb1525",
   "metadata": {},
   "source": [
    "# 📌 Conclusion\n",
    "\n",
    "The BERT-based fake news detection model achieved good performance on the validation set using just 2 epochs. With metrics like precision, recall, and F1-score computed, we see that BERT can understand and differentiate between fake and real news effectively.\n",
    "\n",
    "### Key Takeaways:\n",
    "- BERT effectively captures contextual nuances in text classification.\n",
    "- The model performed well even with limited epochs and preprocessing.\n",
    "- Fine-tuning pre-trained models is a powerful technique for NLP tasks.\n",
    "\n",
    "### ✅ Future Scope:\n",
    "- Train for more epochs or fine-tune hyperparameters.\n",
    "- Use a larger and more diverse dataset.\n",
    "- Deploy the model via a web app or REST API.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e16b401-7781-4e8c-a8c3-f7bcfb8c60db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941e58f5-8f03-4d66-92bf-0042b9106a93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-env)",
   "language": "python",
   "name": "tf-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
